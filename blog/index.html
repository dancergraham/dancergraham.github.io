<!doctype html>
<html lang="en">
<head>
<meta charset="utf-8">
<link rel="stylesheet" href="../static/style.css">
<link rel="stylesheet" href="../static/pygments.css">
<link rel="icon" type="image/x-icon" href="../static/favicon.ico">
<meta name="viewport" content="width=device-width">

  <meta name="og:title" content="Graham Knapp's Blog">
  <meta name="title" property="og:title" content="Graham Knapp's Blog">

<meta name="author" content="Graham Knapp">

  <meta name="og:description"
      content="Graham Knapp's homepage and blog.  Graham is a British Engineer and musician living in France">
  <meta name="description" property="og:description"
      content="Graham Knapp's homepage and blog.  Graham is a British Engineer and musician living in France">

<meta name="image" property="og:image" content="../GrahamKnapp.png" />

<title>Graham Knapp ‚Äî blog</title>
</head>
<body>
<header>
    <h1><a href="../">Graham Knapp</a></h1>

    <nav>
        <ul class="nav navbar-nav">
            <li><a href="../">Welcome</a></li>
            
                <li class="active"><a href="./">Blog</a>
                </li>
            
                <li><a href="../contact/">Contact</a>
                </li>
            
                <li><a href="../about/">About</a>
                </li>
            
            <li><a href="/feed.xml"><img src="../static/rss-feed.png" title="RSS Feed" alt="RSS Feed"
                                                 style="width: 24px; height: 24px;"></a></li>
        </ul>
    </nav>
    <div>

    </div>
</header>
<div class="page">
    
    
  
    <a href="tags/ai/" class="tag" title="AI articles">AI</a>
  
    <a href="tags/bookmarks/" class="tag" title="bookmarks articles">bookmarks</a>
  
    <a href="tags/design-patterns/" class="tag" title="design patterns articles">design patterns</a>
  
    <a href="tags/django/" class="tag" title="django articles">django</a>
  
    <a href="tags/e57/" class="tag" title="e57 articles">e57</a>
  
    <a href="tags/feature-flags/" class="tag" title="feature flags articles">feature flags</a>
  
    <a href="tags/pointcloud/" class="tag" title="pointcloud articles">pointcloud</a>
  
    <a href="tags/python/" class="tag" title="python articles">python</a>
  
    <a href="tags/rhino-3d/" class="tag" title="Rhino 3D articles">Rhino 3D</a>
  
    <a href="tags/talks/" class="tag" title="talks articles">talks</a>
  
    <a href="tags/typescript/" class="tag" title="TypeScript articles">TypeScript</a>
  
    <a href="tags/wind-engineering/" class="tag" title="wind engineering articles">wind engineering</a>
  

    
        <div>
            
            
  <div class="blog-post">
  
    <h2><a href="nantes-na-jamais-ete-en-bretagne/">Nantes n&#39;a jamais √©t√© en Bretagne üîó</a></h2>
  
  <p class="meta">
    written by
    
      <a href="https://hachyderm.io/@graham_knapp">Graham Knapp</a>
    
    on 2025-10-19
  </p>
      
          <p>Une √©lue de la r√©gion Nantaise m'a r√©cemment dit ¬´<em>Nantes n'a jamais √©t√© en Bretagne</em>¬ª, phrase que j'ai entendu plusieurs fois depuis que j'ai d√©m√©nage dans la r√©gion. Et si je vous disais que cette affirmation est √† la fois parfaitement vraie et compl√®tement fausse ?</p>
<p>Oui c'est vraie - Nantes n'a jamais √©t√© en "Bretagne", mais seulement depuis la cr√©ation de r√©gions administratives modernes, dont la R√©gion Bretagne, en 1959. Avant cela, Bretagne voulait exclusivement dire la zone culturelle, g√©ographique et politique de l'ouest de la France. 
<br><br><a href="nantes-na-jamais-ete-en-bretagne/">Read Full Post</a></p>

        </div>

        </div>
        <hr>
    
        <div>
            
            
  <div class="blog-post">
  
    <h2><a href="looking-beyond-code-customer-support/">Looking beyond code - AI for a beginner&#39;s mind üîó</a></h2>
  
  <p class="meta">
    written by
    
      <a href="https://hachyderm.io/@graham_knapp">Graham Knapp</a>
    
    on 2025-10-09
  </p>
      
          <p>Most of the research on large language models (LLMs) suggests a familiar pattern: experts, already skilled in their field, benefit most from AI assistance. So I was surprised to come across <a href="https://academic.oup.com/qje/article/140/2/889/7990658">a study in The Quarterly Journal of Economics</a> that seems to show the opposite:</p>
<blockquote><p><em>"Less skilled and less experienced workers improve significantly across all productivity measures, including a 30% increase in the number of issues resolved per hour... AI has little effect on the productivity of higher-skilled or more experienced workers"</em></p>
</blockquote>
<p>Note that this finding comes from a very specific context: customer support for business software. Here, the AI was trained on the full archive of support calls, tasks are relatively uniform, and staff turnover is high. In that environment, AI not only boosted productivity but also reduced customer complaints and helped retain new employees. Still, the result raises a broader question: where might we benefit from this effect? Perhaps in any domain where we are thrown into unfamiliar work and the AI has access to rich, relevant training data.</p>
<p>The study also suggests a way forward: when novices follow AI recommendations closely, they not only become more productive in the moment but also retain those improvements when the AI support is removed. That‚Äôs encouraging ‚Äî it hints that AI can be more than a crutch. Used well, it can help us build lasting skills and confidence, rather than leaving us permanently dependent on the machine.</p>

        </div>

        </div>
        <hr>
    
        <div>
            
            
  <div class="blog-post">
  
    <h2><a href="my-copilot-instructions-file/">What&#39;s in my Copilot instructions file, and why? üîó</a></h2>
  
  <p class="meta">
    written by
    
      <a href="https://hachyderm.io/@graham_knapp">Graham Knapp</a>
    
    on 2025-09-22
  </p>
      
          <p>Following my article on <a href="adopting-llms-in-a-startup/">adopting LLMs in a startup</a>, I was asked about the <a href="https://docs.github.com/en/copilot/how-tos/configure-custom-instructions/add-repository-instructions">GitHub Copilot instructions file</a> I maintain for one of our core projects. I‚Äôd like to explain what‚Äôs in that file, why it‚Äôs structured the way it is, and how it differs from standard Python/Django agents guideline templates.</p>
<p>My team uses GitHub Copilot in 3 main ways in VSCode and JetBrains PyCharm:</p>
<ol>
<li><strong>Autocomplete on steroids</strong> - the classic in-IDE use case.</li>
<li><strong>Copilot Chat / Edit</strong> - in-IDE discussions or targeted edits on specific files or sections</li>
<li><a href="testing-github-copilot-agent-mode"><strong>Agentic coding</strong></a> - in a dedicated environment on GitHub or in the IDE</li>
</ol>
<p>This file is used in Copilot Chat/Edit and in agentic coding sessions ‚Äî not for raw autocomplete.</p>
<h3>What‚Äôs in the file</h3>
<p>My copilot instructions markdown file is a <strong>project overview</strong> ‚Äî a map of the terrain rather than a rulebook. It gives LLMs, but also developers, the essential context to work productively without overloading the context window. It covers:
<br><br><a href="my-copilot-instructions-file/">Read Full Post</a></p>

        </div>

        </div>
        <hr>
    
        <div>
            
            
  <div class="blog-post">
  
    <h2><a href="bookmark-the-technological-republic/">Bookmark: The Technological Republic by Karp &amp; Zamiska (2024) üîó</a></h2>
  
  <p class="meta">
    written by
    
      <a href="https://hachyderm.io/@graham_knapp">Graham Knapp</a>
    
    on 2025-09-19
  </p>
      
          <p>A surprisingly engaging read, the authors set out a strong argument that Silicon Valley doesn't stand for much of any importance, followed by some rather fragmented arguments and opinions on what should be done about it.</p>
<p>Part 1 describes the current state of Silicon Valley as the authors see it, highlighting the reluctance of many tech firms to engage in military, policing or surveillance contracts. For me this highlights their refusal to engage with no real opposition or alternative. They seem to hanker for a stronger pro-American attitude from their big tech colleagues.
<br><br><a href="bookmark-the-technological-republic/">Read Full Post</a></p>

        </div>

        </div>
        <hr>
    
        <div>
            
            
  <div class="blog-post">
  
    <h2><a href="adopting-llms-in-a-startup/">Adopting LLMs in a startup üîó</a></h2>
  
  <p class="meta">
    written by
    
      <a href="https://hachyderm.io/@graham_knapp">Graham Knapp</a>
    
    on 2025-09-14
  </p>
      
          <p>I have been gradually increasing my use of LLM tools since 2022 when I started experimenting with the preview version of GitHub Copilot before encouraging my team to try it out. But adopting AI tools effectively requires more than just signing up for ChatGPT or GitHub Copilot. From my own experience testing and deploying AI across different workflows alone and in a team, here are some practical lessons worth sharing.</p>
<h3>1. Be Clear About Context and ‚ÄúWhy‚Äù</h3>
<p>AI works best when you don‚Äôt just tell it <em>what</em> to do, but also <em>why</em>. For example, instead of asking ‚Äúwrite a sales pitch,‚Äù tell it what audience you‚Äôre targeting, what problem they have, and why your product solves it. This mirrors how we delegate tasks to humans: explaining the reasoning improves the output.
<br><br><a href="adopting-llms-in-a-startup/">Read Full Post</a></p>

        </div>

        </div>
        <hr>
    
        <div>
            
            
  <div class="blog-post">
  
    <h2><a href="always-say-please-never-say-thank-you-to-your-llm/">Always say &#34;Please&#34;, never say &#34;Thank you&#34; to your LLM üîó</a></h2>
  
  <p class="meta">
    written by
    
      <a href="https://hachyderm.io/@graham_knapp">Graham Knapp</a>
    
    on 2025-09-10
  </p>
      
          <p>We've all been there ‚Äì that moment when you catch yourself thanking your AI assistant. But could that simple 'thank you' could have more environmental impact than you think?</p>
<p>LLMs run on tokens - one token is roughly equivalent to one word so when you say 'please,' you're feeding 1 extra token into your request. In an average  3-turn conversation with an LLM the LLM will re-read that token 3 times, so that's a cost of 3 extra tokens in an exchange which probably includes many hundreds or thousands of tokens.</p>
<p>But when you say 'thank you,' the AI has to reprocess the entire conversation from start to finish, plus the extra "thank you", taking up significantly more resources. Where "Please" costs 3 tokens, "thank you" costs an extra api call with many hundreds of tokens.</p>
<p>Lets avoid "thank you" but with the new generation of AI tools having memory, saying 'please' can help the AI understand your personality and communication style better over time. <a href="https://arxiv.org/html/2402.14531v1">Yin et al (2024)</a> show us that it may give better results - but don't overdo it! Overly polite requests can degrade results.</p>
<p>OK so mind your Qs, please and thank you for reading!</p>

        </div>

        </div>
        <hr>
    
        <div>
            
            
  <div class="blog-post">
  
    <h2><a href="bookmark-system-design-interview-an-insiders-guide-by-alex-xu/">Bookmark: System Design Interview: An Insider‚Äôs Guide by Alex Xu üîó</a></h2>
  
  <p class="meta">
    written by
    
      <a href="https://hachyderm.io/@graham_knapp">Graham Knapp</a>
    
    on 2025-09-10
  </p>
      
          <p>A structured guide to approaching system design interview questions using real-world case studies and a repeatable framework‚Äîfrom scaling basics to designing complex systems.</p>
<h3>‚Äã Key Ideas / Takeaways</h3>
<p>Alex Introduces a <strong>4-step framework</strong> to tackle system design questions:</p>
<ol>
<li>Understand the problem and establish the scope  </li>
<li>Propose a high-level design and get buy-in from the interviewer  </li>
<li>Dive deep into chosen components </li>
<li>Wrap up with optimizations, bottlenecks, and improvements </li>
</ol>
<p>I found this really useful for demystifying the process and giving some structure to help tackle this kind of interview. The repetition helps to reinforce the process.
<br><br><a href="bookmark-system-design-interview-an-insiders-guide-by-alex-xu/">Read Full Post</a></p>

        </div>

        </div>
        <hr>
    
        <div>
            
            
  <div class="blog-post">
  
    <h2><a href="testing-github-copilot-agent-mode/">Testing GitHub Copilot agent mode üîó</a></h2>
  
  <p class="meta">
    written by
    
      <a href="https://hachyderm.io/@graham_knapp">Graham Knapp</a>
    
    on 2025-08-23
  </p>
      
          <p>I tested GitHub Copilot agent mode in July 2025, setting Copilot to work online on different sized features - the workflow looks like this:</p>
<ol>
<li>Chat with Copilot online - ask it to open a PR to work on a specific feature. Copilot starts working in its own virtual machine on GitHub.</li>
<li>30 minutes later I get an email saying the PR is ready for review - I read it online and ask for any corrections via github.com</li>
<li>If and when I am happy with it I pull the branch to my PC, review, modify, fix, change.</li>
<li>I push from my machine and merge to trunk</li>
</ol>
<p>Some stats:</p>
<ul>
<li>19 Pull requests opened against our main monorepo in 5 weeks. </li>
<li>7 merged</li>
<li>8 still open on the 31st of July (3 of those created on the final day)</li>
<li>3 closed unmerged because they clearly didn't work or were not worth finishing</li>
<li>1 closed because I reimplemented it more successfully on my dev PC</li>
</ul>
<p>For example, I tasked Copilot with refactoring 3 instances of near-duplicate code into a common service and make some improvements to error handling on the refactored service. My experience of code review from the last 4 years definitely helps with this workflow - reviewing code from an agent is similar to reviewing colleagues' code except that I don't feel guilty about leaving a PR unread for more than a day. Those PRs still become stale however and merge conflicts are a pain if the agent changes overlap with other PRs.</p>
<p>One challenge is that this makes it very easy to set Copilot working on easy to define low-impact work but that work still takes to review. It would be easy to get into the habit of doing lots of unimportant busy work with this workflow. I now want to explore how to use coding agents to achieve more ambitious changes, perhaps changes I would not take on individually because they lie near the limits of my current knowledge.</p>

        </div>

        </div>
        <hr>
    
        <div>
            
            
  <div class="blog-post">
  
    <h2><a href="playing-in-my-bag-with-llm-agent-templates/">Playing &#34;In my bag...&#34; with LLM agent templates üîó</a></h2>
  
  <p class="meta">
    written by
    
      <a href="https://hachyderm.io/@graham_knapp">Graham Knapp</a>
    
    on 2025-08-10
  </p>
      
          <p>There's a memory game "In my bag..." where you pretend you have a list of things in your bag "In my bag I have a comb and a cat". The next person in the circle has to list all the same things and add one more at the end "In my bag I have a comb, a cat and a clock". The game ends when someone makes a mistake or gives up.</p>
<p>It occurred to me that this is a great analogy for the templates used in LLM chatbots! Every time you chat with an LLM the LLM re-reads the whole history of the conversation before responding. This is why they get slower over time, particularly if they are making web searches, viewing images, using MCPs or other tools which add a lot of hidden tokens to the chat history.</p>
<p><a href="https://github.com/ollama/ollama/blob/main/docs/template.md">The ollama docs describe a simple template here</a></p>

        </div>

        </div>
        <hr>
    
        <div>
            
            
  <div class="blog-post">
  
    <h2><a href="feature-flags-pt-3-djangocon/">Feature flags Pt 3: Deploy to some of the people all of the time, and all of the people some of the time! üîó</a></h2>
  
  <p class="meta">
    written by
    
      <a href="https://hachyderm.io/@graham_knapp">Graham Knapp</a>
    
    on 2025-04-25
  </p>
      
          <p>My talk from DjangoCon Europe 2025 - I discuss:</p>
<ol>
<li>What are Feature Flags ?</li>
<li>Why use Feature Flags ?</li>
<li>How Acernis uses Feature Flags</li>
<li>Getting started with Feature Flags in Python and Django</li>
</ol>
<p><img src="feature-flags-pt-3-djangocon/preview.jpg" alt="Preview image from the talk">
<br><br><a href="feature-flags-pt-3-djangocon/">Read Full Post</a></p>

        </div>

        </div>
        <hr>
    

    
  <div class="pagination">
    
      <span class="disabled">&laquo; Previous</span>
    
    | 1 |
    
      <a href="page/2/">Next &raquo;</a>
    
  </div>


</div>
<footer>
    &copy; Copyright 2019 - 2025 by Graham Knapp.
</footer>
</body>
</html>
